// hls-fpga-machine-learning `TODO: make imports dynamic at writer level` imports
#include "dynamatic/Integration.h"
#include "stdlib.h"
#include "stdio.h"
#include "nnet_utils/fc.h"

// hls-fpga-machine-learning `TODO: make preicison dynamic at writer level` insert layer precision
#define NB_DEFAULT 16
#define INT_DEFAULT 6
#define FRAC_DEFAULT NB_DEFAULT - INT_DEFAULT

#define NB_ACC  32
#define INT_ACC 12
#define FRAC_ACC NB_ACC - INT_ACC

typedef long dense_accum_t;
typedef int default_t;

// hls-fpga-machine-learning insert dimensions
#define N_INPUT_1_1 21
#define N_LAYER_2 32
#define N_LAYER_5 32
#define N_LAYER_8 32
#define N_LAYER_11 3


// hls-fpga-machine-learning load weights
const default_t w1[N_LAYER_2][N_INPUT_1_1] = {
    245,-260,268,-20,-45,284,0,-42,-136,-121,151,5,2,28,0,19,-1674,32,15,-442,-90,
    -397,-279,168,0,22,208,0,102,213,242,151,-98,0,0,0,-17,12,-1,208,9,-3,
    301,-36,55,-245,20,99,-91,-443,19,-99,229,187,-104,55,0,20,2225,-408,-116,152,-614,
    309,234,20,-98,-187,-393,53,8,141,-36,-5,-24,65,-109,0,193,-1750,524,255,-414,476,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    -86,331,227,-47,-2,-359,0,357,233,-10,-11,118,0,-59,0,-3,-1434,125,188,-287,434,
    -4,-155,-45,-22,90,19,3,2,17,-14,235,5,2,3,0,3,-2684,18,-78,-9,30,
    74,185,-36,64,-3,-9,0,-25,-36,198,0,-6,0,3,0,96,-251,0,-201,-25,44,
    0,-125,148,161,-8,29,0,0,-8,-4,-13,9,2,254,0,36,-1700,1,-64,-27,-59,
    262,284,121,86,140,-149,0,-61,217,66,-160,110,4,271,0,276,-2143,203,47,-67,-104,
    344,-234,174,-68,-248,-42,0,-139,-111,-156,-359,222,1,-54,0,279,-1385,43,-138,-2,599,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    72,-193,184,-56,157,-93,0,-39,171,-58,296,-204,1,259,0,264,-1306,15,-64,-87,479,
    33,-146,111,-132,142,280,0,-87,137,-2,180,-43,88,49,0,191,-2079,681,491,1,286,
    273,-91,-13,63,265,-120,3,355,-167,30,-18,-18,9,-37,1,-38,-2431,303,160,-213,39,
    -69,26,38,12,113,19,-3,-8,34,179,-282,-58,-8,187,0,126,1805,-177,229,436,171,
    12,-4,11,0,2,-1,0,0,-2,17,0,0,0,0,0,0,0,0,0,0,0,
    -114,-23,281,16,-99,124,0,116,-114,152,-86,-89,3,-58,0,-243,-1631,513,336,265,688,
    117,275,-59,239,-54,20,0,-54,1,251,259,1,0,301,0,-249,-1948,402,372,-97,100,
    256,-216,-309,210,8,67,0,-188,7,-72,235,-4,0,20,0,374,1486,-101,-30,360,46,
    131,-68,-55,198,27,-177,-2,-11,4,-29,-4,-111,-9,183,0,-37,1903,-237,134,156,-192,
    58,288,21,-346,164,-193,-3,-51,-25,243,161,0,-65,-31,-1,4,2262,-344,-205,180,-453,
    263,-263,365,-149,121,280,0,-19,-17,176,85,22,-1,-1,0,100,1867,-228,-255,97,-210,
    296,-197,-110,2,5,259,0,-186,173,-164,226,-1,0,-4,0,-82,689,0,440,166,73,
    -84,-18,90,-128,184,-206,0,-62,-10,137,-433,257,4,-56,0,-107,-1784,652,414,-24,480,
    161,-128,-124,0,183,253,0,332,-40,327,-30,186,0,299,0,208,-888,181,423,1,284,
    -184,205,118,0,150,0,0,0,214,-143,212,-125,0,107,0,172,-1102,0,-51,100,-133,
    100,200,234,-2,-6,-52,0,2,44,-91,105,-4,0,3,0,46,-857,0,-57,46,-71,
    26,146,-60,-7,-39,-32,1,-18,-36,-94,-147,147,10,-29,0,-23,-2164,437,-140,-132,-90,
    -66,-18,28,-44,-2,176,232,-100,-12,16,325,49,6,-42,0,-204,-2128,390,614,184,302,
    102,300,445,0,5,-246,0,-12,139,-419,-13,-12,-1,191,0,0,866,-45,89,39,-116
};
const default_t b1[N_LAYER_2] = {
    41,-5,71,0,-37,-65,53,52,7,35,16,30,-64,21,72,79,38,-4,57,18,80,22,120,15,1,67,33,-48,9,71,63,-19
};
const default_t w3[N_LAYER_5][N_LAYER_2] = {
    199,57,-312,45,0,0,308,133,161,249,303,69,0,113,-2,471,-452,0,221,175,-161,-295,-324,-15,-22,47,-38,123,-109,159,154,236,
    -10,6,-5,20,0,0,-110,2,102,-14,17,-3,0,4,266,-7,55,0,3,144,252,1,1,15,31,20,147,1,-3,3,396,-349,
    325,388,-458,301,0,0,114,446,241,222,291,0,0,40,441,337,-264,34,451,-82,-191,-221,-364,-352,67,347,120,228,305,337,370,-10,
    -1,0,0,0,0,0,-2,3,0,-1,0,-1,0,0,0,0,0,0,-3,0,1,1,0,-13,142,0,1,0,-1,-1,1,-2,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    -112,-255,432,-288,0,0,-40,-232,25,-108,29,73,0,-45,-135,-472,124,1,-177,97,318,191,400,162,320,-157,-272,-105,-75,-181,-188,191,
    0,0,-95,0,0,0,0,0,0,0,0,153,0,0,17,0,0,0,0,0,-87,0,0,-30,0,0,0,0,106,0,0,0,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    137,0,-107,290,0,0,-3,172,-102,64,177,14,0,151,32,301,-296,0,97,38,-266,-244,-39,-40,-46,0,79,2,-119,84,116,42,
    0,5,-291,298,0,0,1,27,-82,-2,1,235,0,160,28,41,0,0,1,75,-4,-3,-31,-4,-3,0,252,4,-44,132,195,-18,
    96,0,-178,345,0,0,-5,111,-160,229,147,-1,0,123,50,94,-177,0,-1,284,-28,-61,-72,-332,-215,244,-79,65,203,242,-1,177,
    -107,-267,392,-25,0,0,0,-208,99,-112,-22,-53,0,-35,-133,-193,304,0,-244,-255,306,244,454,169,119,-78,-73,-95,25,-174,-140,172,
    323,243,-16,286,0,0,235,86,66,0,-66,329,0,205,390,81,-75,0,1,170,188,-174,-1,-98,-52,335,155,3,111,396,270,-87,
    75,1,-93,-30,0,0,273,125,94,185,51,205,0,-2,357,366,-156,-7,190,-145,-23,-140,-40,-354,-16,-1,128,2,2,212,261,-5,
    59,81,-302,200,0,0,-38,176,-85,265,385,382,0,-1,158,84,-256,-141,211,113,-47,-301,-286,-40,129,40,-15,118,14,364,154,-305,
    219,134,-92,216,0,0,426,149,21,6,196,29,0,152,159,103,-64,153,418,112,-3,-12,-427,-120,-75,275,256,18,-82,137,17,-276,
    -206,-130,223,3,0,0,105,-190,36,-76,-34,-27,0,-116,-3,-318,147,0,-1,-1,385,170,361,283,95,0,2,-1,161,-127,0,-32,
    304,5,-292,0,0,0,-73,237,197,229,303,-14,0,118,320,150,-157,0,363,185,-48,-89,-287,-259,146,194,-65,158,236,108,293,-58,
    9,44,-106,345,0,0,125,525,269,112,98,186,0,6,172,143,-289,-1,-35,230,-69,-325,-488,-182,-12,139,72,56,-209,328,437,-39,
    6,-5,97,-202,0,0,-1,4,11,10,186,-142,0,6,-4,-109,-1,0,-104,-63,4,2,9,156,120,-68,-338,-2,230,-3,0,208,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    1,442,-407,154,0,0,-41,289,20,54,365,297,0,252,484,236,-341,-94,313,287,-8,-399,-288,-325,-2,280,120,152,0,483,484,-308,
    41,10,-358,3,0,0,3,259,53,0,-112,-77,0,105,8,322,-2,0,0,-38,63,-2,-176,-107,-2,240,246,2,162,45,0,192,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    9,0,-122,206,0,0,177,232,128,0,-5,237,0,176,-1,48,-57,0,0,60,-3,-64,-95,-5,-2,-1,-122,2,0,188,-1,-2,
    0,136,-31,122,0,0,-20,450,87,-3,202,6,0,-3,164,46,0,-1,246,212,50,-2,-321,-89,187,375,306,18,33,205,435,-206,
    -2,0,-200,119,0,0,-78,37,-114,2,154,-2,0,36,191,190,-178,0,125,22,11,-34,-262,-14,125,151,192,2,220,174,0,-1,
    250,89,-469,69,0,0,48,377,-179,268,235,278,0,401,204,549,-339,69,-1,387,-132,-361,-155,-435,-154,513,-149,85,43,235,473,-58,
    72,4,-164,286,0,0,0,-3,0,-7,0,114,0,-3,122,47,0,0,5,149,-1,-2,-11,-3,43,116,33,3,9,5,138,-122,
    -21,-3,31,68,0,0,-244,-44,176,-56,-21,-32,0,-49,1,-89,78,0,-16,149,171,128,207,216,4,0,1,-1,-1,-56,0,1,
    -285,-263,591,-261,0,0,-71,-170,20,-143,-234,-152,0,0,-11,-9,372,0,-15,-115,461,276,285,131,61,-97,21,-201,57,-205,-191,163,
    324,106,-352,-19,0,0,225,170,202,169,43,313,0,244,17,222,-126,12,342,14,-56,-82,-365,10,-245,81,-150,74,236,125,6,-1
};
const default_t b3[N_LAYER_5] = {
    7,65,-10,47,-9,151,3,-27,-12,40,17,186,55,-64,9,36,180,-48,-26,71,-20,9,30,-10,4,-17,-29,16,-2,109,111,65
};
const default_t w5[N_LAYER_8][N_LAYER_5] = {
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    -272,223,-38,2,0,606,0,0,-42,1,44,421,177,-11,-249,0,226,-181,-423,0,0,-177,-10,0,0,-92,-168,-457,1,256,545,-98,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    397,200,315,18,0,-462,0,0,44,-2,148,-306,193,370,97,402,-10,237,278,0,0,561,-1,0,112,398,0,676,206,156,-388,148,
    65,0,358,0,0,-17,0,0,0,-1,3,-140,369,0,14,0,3,250,208,-44,0,534,4,0,1,347,-1,264,0,3,-54,165,
    -35,1,-260,0,0,476,0,0,-32,1,-8,426,0,-45,-111,-140,256,-54,-268,145,0,-325,0,0,0,-113,0,-343,1,48,398,-26,
    216,-1,217,-1,0,-226,0,0,116,119,314,-236,-41,2,429,6,-76,127,55,-68,0,520,176,0,110,0,0,266,-1,-47,-192,167,
    69,309,240,0,0,-127,0,0,21,391,20,-103,452,0,421,218,41,229,421,-235,0,832,217,0,1,499,186,510,415,54,-47,-3,
    347,-2,272,21,0,-340,76,0,127,159,33,-280,213,318,266,239,-389,191,18,-68,0,61,0,0,-107,138,-15,605,-1,81,-329,550,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    218,-2,319,135,0,-244,0,0,266,86,3,-275,0,0,80,425,-72,1,414,-19,0,640,-1,0,199,281,-1,431,75,-3,-220,1,
    295,-156,377,-44,0,-240,0,0,55,-67,21,-257,176,414,36,14,-53,90,87,67,0,459,1,0,283,4,69,598,0,-228,-368,321,
    -10,1,-370,176,0,482,0,0,-5,1,-4,461,202,-1,-17,-111,314,-189,-262,182,0,-547,0,0,0,-131,1,-308,1,89,367,-4,
    33,1,-48,0,0,402,-1,0,-4,1,-4,375,61,0,-169,-38,215,-247,-469,297,0,-308,1,0,0,-63,1,-205,1,0,327,-2,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    137,-1,448,0,0,-270,0,0,204,-1,3,-300,207,227,366,162,-167,342,117,0,0,599,149,0,178,0,93,123,-1,-2,-181,2,
    37,-2,19,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,-1,0,0,0,0,0,0,-1,0,0,0,0,-2,3,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    -2,152,-2,1,0,3,0,0,1,1,-131,3,-91,0,-30,0,2,57,0,0,0,0,1,0,0,190,0,-62,2,2,15,-4,
    -19,1,-25,131,0,405,0,0,-239,1,32,354,0,-2,-68,-64,133,-83,-320,0,0,-184,-70,0,23,-7,-141,-99,-51,0,342,-10,
    326,-1,26,26,0,-182,0,0,11,23,185,-221,187,4,188,78,-236,14,45,0,0,390,0,0,0,0,54,282,0,-2,-198,351,
    -52,3,-173,0,0,258,0,0,-55,1,-182,226,1,-1,-21,0,147,-2,-181,0,0,-58,0,0,0,2,0,-178,1,73,344,-100,
    182,0,385,0,0,-113,0,0,0,0,74,-112,170,0,130,0,-208,5,23,-27,0,150,0,0,0,0,138,240,0,-1,-93,52,
    33,-39,351,0,0,-150,0,0,56,-1,184,-189,-46,57,286,116,-49,-19,356,-54,0,392,-1,0,0,248,135,338,-1,-148,-193,0,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    170,-67,466,0,0,-267,0,0,171,184,274,-260,138,30,417,158,-143,153,184,-91,0,298,1,0,73,-93,-61,470,0,-270,-242,148,
    258,-2,246,-145,0,-424,0,0,97,290,71,-271,116,35,284,120,-65,155,88,227,0,206,228,0,165,-101,278,136,0,-2,-479,381,
    55,149,415,194,0,-323,0,0,280,-140,366,-478,250,315,253,216,-126,123,434,-1,0,341,166,0,0,50,102,307,0,-282,-400,45,
    -1,1,-79,0,0,77,0,0,0,1,-2,56,0,0,0,0,0,-76,-1,0,0,-30,2,0,0,1,0,-54,0,1,35,-1,
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
    -67,680,368,112,0,-255,0,0,0,272,150,-81,382,-1,485,476,56,7,467,-104,0,859,-2,0,0,523,24,316,222,127,6,-13
};
const default_t b5[N_LAYER_8] = {
    -3,114,-1,19,62,296,-9,138,5,-16,-3,15,232,154,-19,-1,-2,-13,-10,-7,88,-17,135,-44,-43,-46,11,28,-19,86,-20,143
};
const default_t w7[N_LAYER_11][N_LAYER_8] = {
    0,467,0,-620,-349,539,-118,-848,-280,0,-715,-123,645,660,0,-464,0,0,0,0,467,-8,117,0,-283,0,-334,-148,-262,55,0,-885,
    0,321,0,-54,107,130,-28,266,-479,0,-344,-329,140,108,0,-182,-133,0,0,105,130,-94,216,39,-220,0,-489,-534,-314,22,0,170,
    0,-660,0,490,418,-730,546,470,587,0,102,594,-546,-473,0,219,-28,0,0,-133,-495,493,-434,473,276,0,516,575,519,-203,0,177
};
const default_t b7[N_LAYER_11] = {
    -58,38,-16
};


// ****************************************
// NETWORK INSTANTIATION
// ****************************************
void full_model(
    default_t input_0, 
    default_t input_1, 
    default_t input_2, 
    default_t input_3, 
    default_t input_4, 
    default_t input_5, 
    default_t input_6, 
    default_t input_7, 
    default_t input_8, 
    default_t input_9, 
    default_t input_10, 
    default_t input_11, 
    default_t input_12, 
    default_t input_13, 
    default_t input_14, 
    default_t input_15, 
    default_t input_16, 
    default_t input_17, 
    default_t input_18, 
    default_t input_19, 
    default_t input_20, 
    default_t out8_0[1],
    default_t out8_1[1],
    default_t out8_2[1]
    ) {
    // hls-fpga-machine-learning intermediate stores
    default_t tmp_input[N_INPUT_1_1];
    tmp_input[0] = input_0;
    tmp_input[1] = input_1;
    tmp_input[2] = input_2;
    tmp_input[3] = input_3;
    tmp_input[4] = input_4;
    tmp_input[5] = input_5;
    tmp_input[6] = input_6;
    tmp_input[7] = input_7;
    tmp_input[8] = input_8;
    tmp_input[9] = input_9;
    tmp_input[10] = input_10;
    tmp_input[11] = input_11;
    tmp_input[12] = input_12;
    tmp_input[13] = input_13;
    tmp_input[14] = input_14;
    tmp_input[15] = input_15;
    tmp_input[16] = input_16;
    tmp_input[17] = input_17;
    tmp_input[18] = input_18;
    tmp_input[19] = input_19;
    tmp_input[20] = input_20;
    default_t out1[N_LAYER_2];
    default_t out3[N_LAYER_5];
    default_t out5[N_LAYER_8];
    default_t out7[N_LAYER_11];
    default_t out8[N_LAYER_11];

    // hls-fpga-machine-learning insert layers
    dense_accum_t acc1;
    default_t tmp1;
    DENSE_RELU_LAYER(tmp_input, out1, N_INPUT_1_1, N_LAYER_2, w1, b1, acc1, tmp1);
    dense_accum_t acc3;
    default_t tmp3;
    DENSE_RELU_LAYER(out1, out3, N_LAYER_2, N_LAYER_5, w3, b3, acc3, tmp3);
    dense_accum_t acc5;
    default_t tmp5;
    DENSE_RELU_LAYER(out3, out5, N_LAYER_5, N_LAYER_8, w5, b5, acc5, tmp5);
    dense_accum_t acc7;
    default_t tmp7;
    DENSE_LAYER(out5, out7, N_LAYER_8, N_LAYER_11, w7, b7, acc7, tmp7);
    default_t tmp8;
    ARGMAX(out7, out8, N_LAYER_11, tmp8);

    // hls-fpga-machine-learning write outputs
    out8_0[0] = out8[0];
    out8_1[0] = out8[1];
    out8_2[0] = out8[2];
}

int main(void) {
    srand(13);

    // hls-fpga-machine-learning input init
    default_t input[N_INPUT_1_1];
    FILE *f = fopen("input.txt", "r");
    default_t input_0;
    fscanf(f, "%d", &input_0);
    default_t input_1;
    fscanf(f, "%d", &input_1);
    default_t input_2;
    fscanf(f, "%d", &input_2);
    default_t input_3;
    fscanf(f, "%d", &input_3);
    default_t input_4;
    fscanf(f, "%d", &input_4);
    default_t input_5;
    fscanf(f, "%d", &input_5);
    default_t input_6;
    fscanf(f, "%d", &input_6);
    default_t input_7;
    fscanf(f, "%d", &input_7);
    default_t input_8;
    fscanf(f, "%d", &input_8);
    default_t input_9;
    fscanf(f, "%d", &input_9);
    default_t input_10;
    fscanf(f, "%d", &input_10);
    default_t input_11;
    fscanf(f, "%d", &input_11);
    default_t input_12;
    fscanf(f, "%d", &input_12);
    default_t input_13;
    fscanf(f, "%d", &input_13);
    default_t input_14;
    fscanf(f, "%d", &input_14);
    default_t input_15;
    fscanf(f, "%d", &input_15);
    default_t input_16;
    fscanf(f, "%d", &input_16);
    default_t input_17;
    fscanf(f, "%d", &input_17);
    default_t input_18;
    fscanf(f, "%d", &input_18);
    default_t input_19;
    fscanf(f, "%d", &input_19);
    default_t input_20;
    fscanf(f, "%d", &input_20);
    fclose(f);

    default_t out8_0[1];
    default_t out8_1[1];
    default_t out8_2[1];

    CALL_KERNEL(
        full_model,
        input_0, 
        input_1, 
        input_2, 
        input_3, 
        input_4, 
        input_5, 
        input_6, 
        input_7, 
        input_8, 
        input_9, 
        input_10, 
        input_11, 
        input_12, 
        input_13, 
        input_14, 
        input_15, 
        input_16, 
        input_17, 
        input_18, 
        input_19, 
        input_20, 
        out8_0,
        out8_1,
        out8_2
    );
    return 0;
    
}